#!/usr/bin/env python

from argparse import ArgumentParser
from datetime import datetime
from logging import getLogger
from sys import argv
from typing import Iterable

from alma_rest import xml_extract

# provide info for help when called from commandline

parser = ArgumentParser(
    description="For a given fetched_records.job_timestamp extract all MARC21 records and export contents to TSV.",
    epilog="")

help_job_timestamp = "Format 'YYYY-mm-dd HH:MM:SS.000000+0000', pick for set of records from table fetched_records."
parser.add_argument('job_timestamp', type=str, help=help_job_timestamp)

help_tsv_path = "File system path of where you want the tsv saved."
parser.add_argument('tsv_path', type=str, help=help_tsv_path)

help_tsv_header = "Provide your own list of categories you want to extract as a comma-separated list of strings."
parser.add_argument('--tsv-header', type=str, help=help_tsv_header)

parser.add_argument('--split-sf', action='store_true', help="One cell per Subfield.")

help_repetition = """If a field is repeated, concat all contents to one cell with delimiter "|"."""
parser.add_argument('--concat-repetition', action='store_true', help=help_repetition)

args = parser.parse_args()

# set timestamp from argv

timestamp_format = '%Y-%m-%d %H:%M:%S.%f%z'

try:
    job_timestamp = datetime.strptime(argv[1], timestamp_format)
except ValueError:
    logger.error(f"Date in format {timestamp_format} expected.")
    exit(1)


# extract data


def extract_all_keys(all_records: Iterable[dict]) -> list:
    """
    For a as returned by xml_extract.extract_marc_for_job_timestamp
    create a list of all fields for the header of the tsv.
    :param all_records: Generator of all records given as dictionaries
    :return: List of all field-keys within a set of MARC21 records
    """
    list_of_keys = []

    for record_dict in all_records:
        for field_key in record_dict:
            if field_key[0:2] != '00' and field_key != 'leader':
                for field_dict in record_dict[field_key]:

                    ind1 = field_dict['ind1']
                    ind2 = field_dict['ind2']

                    if args.split_sf:
                        for subfield_key in field_dict:
                            if subfield_key[0:3] != 'ind':

                                heading_name = field_key + ind1 + ind2 + subfield_key

                                if heading_name not in list_of_keys:
                                    list_of_keys += [heading_name]

                    else:

                        heading_name = field_key + ind1 + ind2

                        if heading_name not in list_of_keys:
                            list_of_keys += [heading_name]

            else:
                if field_key not in list_of_keys:
                    list_of_keys += [field_key]

    list_of_keys_sorted = sorted(list_of_keys)
    # put leader first, which will otherwise sort to last
    list_of_keys_sorted.insert(0, list_of_keys_sorted.pop())

    return list_of_keys_sorted


gen_record_dicts = xml_extract.extract_marc_for_job_timestamp(job_timestamp)

if args.tsv_header:
    tsv_columns = args.tsv_header.split(',')
else:
    tsv_columns = extract_all_keys(gen_record_dicts)


# gen_record_dicts = xml_extract.extract_marc_for_job_timestamp(job_timestamp)
#
# with open(tsv_path, 'w') as tsv_file:
#     writer = DictWriter(tsv_file, fieldnames=tsv_columns, delimiter='\t')
#     writer.writeheader()
#     for record in gen_record_dicts:
#         writer.writerow(record)
